{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c75140a-db38-44fb-b90c-bfc6a6fcae7b",
   "metadata": {},
   "source": [
    "# This Notebook is for converting Waymo TF-Records to json files that represent a scene standalone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf2c7b15-5ead-4557-a872-d98c3a728240",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAYMO_TF_RECORD_FILE_PATH = '/home/yz8733/Github/isaac-rl/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc56c45e-8daf-48b3-8a8e-76a039bb8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "waymo_record_folder = Path(WAYMO_TF_RECORD_FILE_PATH)\n",
    "\n",
    "\n",
    "\n",
    "from google.protobuf import text_format\n",
    "from waymo_open_dataset.metrics.ops import py_metrics_ops\n",
    "from waymo_open_dataset.metrics.python import config_util_py as config_util\n",
    "from waymo_open_dataset.protos import motion_metrics_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "129a24e0-eac0-4698-ba0e-2e6ede9e5a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_map_samples = 30000\n",
    "\n",
    "# Example field definition\n",
    "roadgraph_features = {\n",
    "    'roadgraph_samples/dir': tf.io.FixedLenFeature(\n",
    "        [num_map_samples, 3], tf.float32, default_value=None\n",
    "    ),\n",
    "    'roadgraph_samples/id': tf.io.FixedLenFeature(\n",
    "        [num_map_samples, 1], tf.int64, default_value=None\n",
    "    ),\n",
    "    'roadgraph_samples/type': tf.io.FixedLenFeature(\n",
    "        [num_map_samples, 1], tf.int64, default_value=None\n",
    "    ),\n",
    "    'roadgraph_samples/valid': tf.io.FixedLenFeature(\n",
    "        [num_map_samples, 1], tf.int64, default_value=None\n",
    "    ),\n",
    "    'roadgraph_samples/xyz': tf.io.FixedLenFeature(\n",
    "        [num_map_samples, 3], tf.float32, default_value=None\n",
    "    ),\n",
    "}\n",
    "# Features of other agents.\n",
    "state_features = {\n",
    "    'state/id':\n",
    "        tf.io.FixedLenFeature([128], tf.float32, default_value=None),\n",
    "    'state/type':\n",
    "        tf.io.FixedLenFeature([128], tf.float32, default_value=None),\n",
    "    'state/is_sdc':\n",
    "        tf.io.FixedLenFeature([128], tf.int64, default_value=None),\n",
    "    'state/tracks_to_predict':\n",
    "        tf.io.FixedLenFeature([128], tf.int64, default_value=None),\n",
    "    'state/current/bbox_yaw':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/height':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/length':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/timestamp_micros':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.int64, default_value=None),\n",
    "    'state/current/valid':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.int64, default_value=None),\n",
    "    'state/current/vel_yaw':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/velocity_x':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/velocity_y':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/width':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/x':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/y':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/current/z':\n",
    "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
    "    'state/future/bbox_yaw':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/height':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/length':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/timestamp_micros':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.int64, default_value=None),\n",
    "    'state/future/valid':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.int64, default_value=None),\n",
    "    'state/future/vel_yaw':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/velocity_x':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/velocity_y':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/width':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/x':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/y':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/future/z':\n",
    "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
    "    'state/past/bbox_yaw':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/height':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/length':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/timestamp_micros':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.int64, default_value=None),\n",
    "    'state/past/valid':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.int64, default_value=None),\n",
    "    'state/past/vel_yaw':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/velocity_x':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/velocity_y':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/width':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/x':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/y':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "    'state/past/z':\n",
    "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
    "}\n",
    "\n",
    "traffic_light_features = {\n",
    "    'traffic_light_state/current/state':\n",
    "        tf.io.FixedLenFeature([1, 16], tf.int64, default_value=None),\n",
    "    'traffic_light_state/current/valid':\n",
    "        tf.io.FixedLenFeature([1, 16], tf.int64, default_value=None),\n",
    "    'traffic_light_state/current/x':\n",
    "        tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
    "    'traffic_light_state/current/y':\n",
    "        tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
    "    'traffic_light_state/current/z':\n",
    "        tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
    "    'traffic_light_state/past/state':\n",
    "        tf.io.FixedLenFeature([10, 16], tf.int64, default_value=None),\n",
    "    'traffic_light_state/past/valid':\n",
    "        tf.io.FixedLenFeature([10, 16], tf.int64, default_value=None),\n",
    "    'traffic_light_state/past/x':\n",
    "        tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
    "    'traffic_light_state/past/y':\n",
    "        tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
    "    'traffic_light_state/past/z':\n",
    "        tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
    "}\n",
    "\n",
    "features_description = {}\n",
    "features_description.update(roadgraph_features)\n",
    "features_description.update(state_features)\n",
    "features_description.update(traffic_light_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45bfac6-c0e3-4eba-9fc2-e883842b3bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uncompressed_tf_example_training_training_tfexample.tfrecord-00000-of-01000']\n"
     ]
    }
   ],
   "source": [
    "filenames = [\n",
    "    p.name for p in waymo_record_folder.iterdir()\n",
    "    if p.is_file() and p.name.startswith(\"uncompressed_tf_example\")\n",
    "]\n",
    "\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "520121ec-d92f-4fac-a3ba-4dc8ebb3f17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncompressed_tf_example_training_training_tfexample.tfrecord-00000-of-01000 Number of Scenes: 455\n"
     ]
    }
   ],
   "source": [
    "parsed = []\n",
    "\n",
    "for file in filenames:\n",
    "    path = os.path.join(WAYMO_TF_RECORD_FILE_PATH, file)\n",
    "    ds = tf.data.TFRecordDataset(path, compression_type=\"\")\n",
    "\n",
    "    n = 0\n",
    "    for raw in ds:  # raw is a tf.Tensor of type string (bytes)\n",
    "        ex = tf.io.parse_single_example(raw, features_description)\n",
    "        parsed.append(ex)\n",
    "        n += 1\n",
    "\n",
    "    print(file, \"Number of Scenes:\", n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d43c79b5-dec3-45b7-8fa3-507823502106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, hashlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def ensure_dir(p):\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def _to_1d(x):\n",
    "    return np.asarray(x).reshape(-1)\n",
    "\n",
    "def _safe_float(x):\n",
    "    return float(x)  # keep exact float32->python float (no rounding)\n",
    "\n",
    "def order_polyline_pca_xy(xyz: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Order points along dominant XY axis (helps make a polyline).\"\"\"\n",
    "    n = xyz.shape[0]\n",
    "    if n <= 2:\n",
    "        return np.arange(n)\n",
    "    p = xyz[:, :2].astype(np.float64)\n",
    "    p0 = p.mean(axis=0, keepdims=True)\n",
    "    X = p - p0\n",
    "    _, _, vt = np.linalg.svd(X, full_matrices=False)\n",
    "    axis = vt[0]\n",
    "    s = X @ axis\n",
    "    return np.argsort(s)\n",
    "\n",
    "def _hash_bytes(b: bytes) -> str:\n",
    "    return hashlib.md5(b).hexdigest()\n",
    "\n",
    "# -----------------------------\n",
    "# Extract everything Waymo provides (no filtering, no downsampling)\n",
    "# -----------------------------\n",
    "def extract_road_polylines_all(parsed_ex, order_points=True):\n",
    "    \"\"\"\n",
    "    Keep ALL roadgraph_samples groups by (type,id), with ALL points.\n",
    "    If order_points=False, the points are kept in the TFRecord order (not recommended for polylines).\n",
    "    \"\"\"\n",
    "    rg_valid = _to_1d(parsed_ex[\"roadgraph_samples/valid\"].numpy()).astype(bool)\n",
    "    rg_xyz   = parsed_ex[\"roadgraph_samples/xyz\"].numpy()          # (30000,3)\n",
    "    rg_dir   = parsed_ex[\"roadgraph_samples/dir\"].numpy()          # (30000,3)\n",
    "    rg_id    = _to_1d(parsed_ex[\"roadgraph_samples/id\"].numpy())   # (30000,)\n",
    "    rg_type  = _to_1d(parsed_ex[\"roadgraph_samples/type\"].numpy()) # (30000,)\n",
    "\n",
    "    # only remove invalid points (that's not \"downsampling\"; it's required)\n",
    "    xyz   = rg_xyz[rg_valid]\n",
    "    direc = rg_dir[rg_valid]\n",
    "    ids   = rg_id[rg_valid].astype(np.int64)\n",
    "    types = rg_type[rg_valid].astype(np.int64)\n",
    "\n",
    "    # group by (type,id)\n",
    "    keys = np.stack([types, ids], axis=1)  # (M,2)\n",
    "    uniq, inv = np.unique(keys, axis=0, return_inverse=True)\n",
    "\n",
    "    polylines = []\n",
    "    for gi, (t, i) in enumerate(uniq):\n",
    "        m = (inv == gi)\n",
    "        pts = xyz[m]\n",
    "        d   = direc[m]\n",
    "\n",
    "        if order_points:\n",
    "            idx = order_polyline_pca_xy(pts)\n",
    "            pts = pts[idx]\n",
    "            d   = d[idx]\n",
    "\n",
    "        polylines.append({\n",
    "            \"type\": int(t),\n",
    "            \"id\": int(i),\n",
    "            \"n\": int(pts.shape[0]),\n",
    "            \"xyz\": pts.tolist(),   # keep full precision lists\n",
    "            \"dir\": d.tolist(),\n",
    "        })\n",
    "\n",
    "    stats = {\n",
    "        \"road_valid_points\": int(xyz.shape[0]),\n",
    "        \"num_groups_total\": int(uniq.shape[0]),\n",
    "        \"num_polylines_saved\": int(len(polylines)),\n",
    "    }\n",
    "    return polylines, stats\n",
    "\n",
    "def extract_agents_start_end_all_valid(parsed_ex, end_mode=\"last_valid\"):\n",
    "    \"\"\"\n",
    "    Save start pose for every valid agent; save end pose from future (last valid).\n",
    "    \"\"\"\n",
    "    cur_valid = _to_1d(parsed_ex[\"state/current/valid\"].numpy()).astype(bool)\n",
    "    is_sdc    = _to_1d(parsed_ex[\"state/is_sdc\"].numpy()).astype(bool)\n",
    "\n",
    "    # (optional) type/id are float32 in your parse; keep them but cast safely\n",
    "    a_type = _to_1d(parsed_ex[\"state/type\"].numpy())\n",
    "    a_id   = _to_1d(parsed_ex[\"state/id\"].numpy())\n",
    "\n",
    "    cx   = _to_1d(parsed_ex[\"state/current/x\"].numpy())\n",
    "    cy   = _to_1d(parsed_ex[\"state/current/y\"].numpy())\n",
    "    cz   = _to_1d(parsed_ex[\"state/current/z\"].numpy())\n",
    "    cyaw = _to_1d(parsed_ex[\"state/current/bbox_yaw\"].numpy())\n",
    "\n",
    "    f_valid = parsed_ex[\"state/future/valid\"].numpy().astype(bool)   # (128,80)\n",
    "    fx   = parsed_ex[\"state/future/x\"].numpy()\n",
    "    fy   = parsed_ex[\"state/future/y\"].numpy()\n",
    "    fz   = parsed_ex[\"state/future/z\"].numpy()\n",
    "    fyaw = parsed_ex[\"state/future/bbox_yaw\"].numpy()\n",
    "\n",
    "    agents = []\n",
    "    for i in np.where(cur_valid)[0]:\n",
    "        start = {\n",
    "            \"x\": _safe_float(cx[i]),\n",
    "            \"y\": _safe_float(cy[i]),\n",
    "            \"z\": _safe_float(cz[i]),\n",
    "            \"yaw\": _safe_float(cyaw[i]),\n",
    "        }\n",
    "\n",
    "        end = None\n",
    "        js = np.where(f_valid[i])[0]\n",
    "        if js.size > 0:\n",
    "            j = int(js[-1] if end_mode == \"last_valid\" else js[0])\n",
    "            end = {\n",
    "                \"x\": _safe_float(fx[i, j]),\n",
    "                \"y\": _safe_float(fy[i, j]),\n",
    "                \"z\": _safe_float(fz[i, j]),\n",
    "                \"yaw\": _safe_float(fyaw[i, j]),\n",
    "                \"t_idx\": int(j),\n",
    "            }\n",
    "\n",
    "        agents.append({\n",
    "            \"track_idx\": int(i),\n",
    "            \"is_sdc\": bool(is_sdc[i]),\n",
    "            \"agent_type\": int(a_type[i]) if np.isfinite(a_type[i]) else None,\n",
    "            \"agent_id\": float(a_id[i]) if np.isfinite(a_id[i]) else None,\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "        })\n",
    "\n",
    "    sdc = [a for a in agents if a[\"is_sdc\"]]\n",
    "    return agents, (sdc[0] if sdc else None)\n",
    "\n",
    "def save_scene_json_full(parsed_ex, out_path, source_file, scene_index_global,\n",
    "                         order_points=True, end_mode=\"last_valid\"):\n",
    "    polylines, road_stats = extract_road_polylines_all(parsed_ex, order_points=order_points)\n",
    "    agents, sdc = extract_agents_start_end_all_valid(parsed_ex, end_mode=end_mode)\n",
    "\n",
    "    payload = {\n",
    "        \"meta\": {\n",
    "            \"source_file\": source_file,\n",
    "            \"scene_index_global\": int(scene_index_global),\n",
    "        },\n",
    "        \"road\": {\n",
    "            \"stats\": road_stats,\n",
    "            \"polylines\": polylines,\n",
    "        },\n",
    "        \"agents\": {\n",
    "            \"count_valid\": int(len(agents)),\n",
    "            \"sdc\": sdc,          # includes start/end\n",
    "            \"items\": agents,     # all valid agents\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(out_path, \"w\") as f:\n",
    "        json.dump(payload, f)\n",
    "\n",
    "def export_tfrecords_to_json_full(filenames, tfrecord_dir, out_dir,\n",
    "                                 features_description, compression_type=\"\",\n",
    "                                 out_name_mode=\"sequential\",\n",
    "                                 order_points=True,\n",
    "                                 end_mode=\"last_valid\"):\n",
    "    \"\"\"\n",
    "    Writes one JSON per TFRecord record (scene). No downsampling, no type filtering.\n",
    "    \"\"\"\n",
    "    ensure_dir(out_dir)\n",
    "    scene_idx = 0\n",
    "\n",
    "    for file in filenames:\n",
    "        path = os.path.join(tfrecord_dir, file)\n",
    "        ds = tf.data.TFRecordDataset(path, compression_type=compression_type)\n",
    "\n",
    "        for raw in ds:\n",
    "            parsed_ex = tf.io.parse_single_example(raw, features_description)\n",
    "\n",
    "            if out_name_mode == \"hash\":\n",
    "                name = f\"scene_{_hash_bytes(raw.numpy())}.json\"\n",
    "            else:\n",
    "                name = f\"scene_{scene_idx:06d}.json\"\n",
    "\n",
    "            out_path = os.path.join(out_dir, name)\n",
    "            save_scene_json_full(\n",
    "                parsed_ex,\n",
    "                out_path=out_path,\n",
    "                source_file=file,\n",
    "                scene_index_global=scene_idx,\n",
    "                order_points=order_points,\n",
    "                end_mode=end_mode,\n",
    "            )\n",
    "            scene_idx += 1\n",
    "\n",
    "    print(\"Done. Total scenes written:\", scene_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82f68680-f41a-4843-b0e5-dff5b716199f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Total scenes written: 455\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = \"/home/yz8733/Github/isaac-rl/data/processed/waymo_scenes_json\"\n",
    "export_tfrecords_to_json_full(\n",
    "    filenames=filenames,\n",
    "    tfrecord_dir=WAYMO_TF_RECORD_FILE_PATH,\n",
    "    out_dir=OUT_DIR,\n",
    "    features_description=features_description,\n",
    "    compression_type=\"\",\n",
    "    out_name_mode=\"sequential\",\n",
    "    order_points=True,   # set False if you truly want raw point order\n",
    "    end_mode=\"last_valid\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b64ca-11da-47a5-a0ec-97f9cc68a82e",
   "metadata": {},
   "source": [
    "#### Debugging blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56fa9499-857a-4822-93ef-1eb0a16df017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: road polylines + start/end poses\n",
    "# -----------------------------\n",
    "\n",
    "def _to_1d(x):\n",
    "    a = np.asarray(x)\n",
    "    return a.reshape(-1)\n",
    "\n",
    "def _to_2d(x, last_dim):\n",
    "    a = np.asarray(x)\n",
    "    a = a.reshape(-1, last_dim)\n",
    "    return a\n",
    "\n",
    "def order_polyline_pca_xy(xyz: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns indices that order points along the dominant 2D axis (XY PCA).\n",
    "    Good enough to turn a grouped point cloud into a polyline.\n",
    "    \"\"\"\n",
    "    n = xyz.shape[0]\n",
    "    if n <= 2:\n",
    "        return np.arange(n)\n",
    "    p = xyz[:, :2].astype(np.float64)\n",
    "    p0 = p.mean(axis=0, keepdims=True)\n",
    "    X = p - p0\n",
    "    # principal axis\n",
    "    _, _, vt = np.linalg.svd(X, full_matrices=False)\n",
    "    axis = vt[0]  # (2,)\n",
    "    s = X @ axis  # (n,)\n",
    "    return np.argsort(s)\n",
    "\n",
    "def extract_road_polylines(parsed_ex, min_points=5, downsample_step=1, order_points=True):\n",
    "    \"\"\"\n",
    "    Build map as grouped polylines from roadgraph_samples/{xyz,dir,id,type,valid}.\n",
    "    Returns a dict with:\n",
    "      - 'polylines': list of dicts: {id, type, xyz(N,3), dir(N,3)}\n",
    "      - 'stats': basic counts\n",
    "    \"\"\"\n",
    "    rg_valid = _to_1d(parsed_ex[\"roadgraph_samples/valid\"].numpy()).astype(bool)\n",
    "    rg_xyz   = parsed_ex[\"roadgraph_samples/xyz\"].numpy()            # (30000,3)\n",
    "    rg_dir   = parsed_ex[\"roadgraph_samples/dir\"].numpy()            # (30000,3)\n",
    "    rg_id    = _to_1d(parsed_ex[\"roadgraph_samples/id\"].numpy())     # (30000,)\n",
    "    rg_type  = _to_1d(parsed_ex[\"roadgraph_samples/type\"].numpy())   # (30000,)\n",
    "\n",
    "    xyz = rg_xyz[rg_valid]\n",
    "    direc = rg_dir[rg_valid]\n",
    "    ids = rg_id[rg_valid].astype(np.int64)\n",
    "    types = rg_type[rg_valid].astype(np.int64)\n",
    "\n",
    "    # group by (type, id)\n",
    "    keys = np.stack([types, ids], axis=1)  # (M,2)\n",
    "    uniq, inv = np.unique(keys, axis=0, return_inverse=True)\n",
    "\n",
    "    polylines = []\n",
    "    for gi, (t, i) in enumerate(uniq):\n",
    "        m = (inv == gi)\n",
    "        pts = xyz[m]\n",
    "        d   = direc[m]\n",
    "        if pts.shape[0] < min_points:\n",
    "            continue\n",
    "\n",
    "        if order_points:\n",
    "            idx = order_polyline_pca_xy(pts)\n",
    "            pts = pts[idx]\n",
    "            d   = d[idx]\n",
    "\n",
    "        if downsample_step > 1:\n",
    "            pts = pts[::downsample_step]\n",
    "            d   = d[::downsample_step]\n",
    "\n",
    "        polylines.append({\n",
    "            \"type\": int(t),\n",
    "            \"id\": int(i),\n",
    "            \"xyz\": pts.astype(np.float32),\n",
    "            \"dir\": d.astype(np.float32),\n",
    "            \"n_points\": int(pts.shape[0]),\n",
    "        })\n",
    "\n",
    "    stats = {\n",
    "        \"road_valid_points\": int(xyz.shape[0]),\n",
    "        \"num_groups_total\": int(uniq.shape[0]),\n",
    "        \"num_polylines_kept\": int(len(polylines)),\n",
    "    }\n",
    "    return {\"polylines\": polylines, \"stats\": stats}\n",
    "\n",
    "def extract_agent_start_end(parsed_ex, use_gt_future_end=True, end_mode=\"last_valid\"):\n",
    "    \"\"\"\n",
    "    Returns list of agents with:\n",
    "      - track_idx\n",
    "      - is_sdc\n",
    "      - start: (x,y,z,yaw)\n",
    "      - end:   (x,y,z,yaw)  (if available)\n",
    "    end_mode: \"last_valid\" or \"first_valid\" over future valid mask.\n",
    "    \"\"\"\n",
    "    cur_valid = _to_1d(parsed_ex[\"state/current/valid\"].numpy()).astype(bool)\n",
    "    is_sdc    = _to_1d(parsed_ex[\"state/is_sdc\"].numpy()).astype(bool)\n",
    "\n",
    "    cx = _to_1d(parsed_ex[\"state/current/x\"].numpy())\n",
    "    cy = _to_1d(parsed_ex[\"state/current/y\"].numpy())\n",
    "    cz = _to_1d(parsed_ex[\"state/current/z\"].numpy())\n",
    "    cyaw = _to_1d(parsed_ex[\"state/current/bbox_yaw\"].numpy())\n",
    "\n",
    "    # optional: future (128,80)\n",
    "    if use_gt_future_end:\n",
    "        f_valid = parsed_ex[\"state/future/valid\"].numpy().astype(bool)\n",
    "        fx = parsed_ex[\"state/future/x\"].numpy()\n",
    "        fy = parsed_ex[\"state/future/y\"].numpy()\n",
    "        fz = parsed_ex[\"state/future/z\"].numpy()\n",
    "        fyaw = parsed_ex[\"state/future/bbox_yaw\"].numpy()\n",
    "\n",
    "    agents = []\n",
    "    idxs = np.where(cur_valid)[0]\n",
    "    for i in idxs:\n",
    "        start = (float(cx[i]), float(cy[i]), float(cz[i]), float(cyaw[i]))\n",
    "        end = None\n",
    "\n",
    "        if use_gt_future_end:\n",
    "            fv = f_valid[i]  # (80,)\n",
    "            js = np.where(fv)[0]\n",
    "            if js.size > 0:\n",
    "                j = int(js[-1] if end_mode == \"last_valid\" else js[0])\n",
    "                end = (float(fx[i, j]), float(fy[i, j]), float(fz[i, j]), float(fyaw[i, j]))\n",
    "\n",
    "        agents.append({\n",
    "            \"track_idx\": int(i),\n",
    "            \"is_sdc\": bool(is_sdc[i]),\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "        })\n",
    "\n",
    "    return agents\n",
    "\n",
    "# -----------------------------\n",
    "# “Inspect” one parsed scene\n",
    "# -----------------------------\n",
    "\n",
    "def inspect_scene(parsed_ex, *, min_points=8, downsample_step=5, order_points=True, max_show=3):\n",
    "    road = extract_road_polylines(\n",
    "        parsed_ex,\n",
    "        min_points=min_points,\n",
    "        downsample_step=downsample_step,\n",
    "        order_points=order_points,\n",
    "    )\n",
    "    agents = extract_agent_start_end(parsed_ex, use_gt_future_end=True, end_mode=\"last_valid\")\n",
    "\n",
    "    print(\"=== Road stats ===\")\n",
    "    print(road[\"stats\"])\n",
    "    print(\"Example polylines:\")\n",
    "    for pl in road[\"polylines\"][:max_show]:\n",
    "        xyz0 = pl[\"xyz\"][0]\n",
    "        xyz1 = pl[\"xyz\"][-1]\n",
    "        print(f\"  (type={pl['type']}, id={pl['id']}) points={pl['n_points']} \"\n",
    "              f\"first=({xyz0[0]:.2f},{xyz0[1]:.2f}) last=({xyz1[0]:.2f},{xyz1[1]:.2f})\")\n",
    "\n",
    "    print(\"\\n=== Agent start/end ===\")\n",
    "    sdc = [a for a in agents if a[\"is_sdc\"]]\n",
    "    print(f\"valid agents: {len(agents)} | sdc count: {len(sdc)}\")\n",
    "    if sdc:\n",
    "        a = sdc[0]\n",
    "        print(\"SDC start (x,y,z,yaw):\", a[\"start\"])\n",
    "        print(\"SDC end   (x,y,z,yaw):\", a[\"end\"])\n",
    "    else:\n",
    "        print(\"No SDC found in this scene (unexpected, but possible in some subsets).\")\n",
    "    non_sdc = [a for a in agents if not a[\"is_sdc\"]]\n",
    "    if non_sdc:\n",
    "        a = non_sdc[0]\n",
    "        print(a[\"start\"],a[\"end\"])\n",
    "\n",
    "    return road, agents\n",
    "\n",
    "# -----------------------------\n",
    "# Usage\n",
    "# -----------------------------\n",
    "# parsed is your list of parsed examples\n",
    "# road, agents = inspect_scene(parsed[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42f6a880-0313-419b-ab12-e11d041597fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Road stats ===\n",
      "{'road_valid_points': 20933, 'num_groups_total': 343, 'num_polylines_kept': 327}\n",
      "Example polylines:\n",
      "  (type=2, id=96) points=57 first=(783.39,1452.30) last=(504.18,1454.57)\n",
      "  (type=2, id=97) points=58 first=(783.72,1455.51) last=(500.70,1457.70)\n",
      "  (type=2, id=99) points=41 first=(782.72,1449.13) last=(584.00,1450.62)\n",
      "\n",
      "=== Agent start/end ===\n",
      "valid agents: 9 | sdc count: 1\n",
      "SDC start (x,y,z,yaw): (571.58447265625, 1450.7574462890625, -147.02467346191406, 3.134042978286743)\n",
      "SDC end   (x,y,z,yaw): (410.5989685058594, 1452.0958251953125, -146.0395050048828, 3.1409289836883545)\n",
      "(587.8990478515625, 1457.5389404296875, -147.53790283203125, 3.1334471702575684) (451.7677307128906, 1458.6298828125, -146.79776000976562, 3.127753496170044)\n"
     ]
    }
   ],
   "source": [
    "road, agents = inspect_scene(parsed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00958319-2c82-4dff-a6cd-760699e0743b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Waymo_py310",
   "language": "python",
   "name": "waymo_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
